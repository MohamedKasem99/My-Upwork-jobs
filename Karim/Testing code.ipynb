{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained my token successfully!\n",
      "{'data': 2, 'error': 'task_on_executing', 'error_Description': \"Task is running! You don't need to start again.\"}\n",
      "{'data': 2, 'error': 'task_on_executing', 'error_Description': \"Task is running! You don't need to start again.\"}\n",
      "{'data': 1, 'error': 'success', 'error_Description': 'Task is started successfully!'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kasem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kasem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import NFile_utils\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfiles_df_list, first_extract, second_extract = NFile_utils.Nfiles_df_list, NFile_utils.first_extract_df, NFile_utils.second_extract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name\n",
       "0  contract\n",
       "1       NDA"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile('strings stems.xlsx')\n",
    "first = pd.read_excel(xls, 'first').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "parent_second = pd.read_excel(xls, 'parent second').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "bad_keywords= pd.read_excel(xls, 'bad keywords').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "at_least_another= pd.read_excel(xls, 'at least another').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "tutoring = pd.read_excel(xls, 'Tutoring').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "payments = pd.read_excel(xls, 'payments').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "contract = pd.read_excel(xls, 'contract').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "second_extract =  pd.read_csv('secondextract.csv').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "pre_process_df_keywords(first)\n",
    "pre_process_df_keywords(parent_second)\n",
    "pre_process_df_keywords(bad_keywords)\n",
    "\n",
    "print('x' in parent_second[\"sound effects\"].values)\n",
    "contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array(['photoshop', 'video editing'], dtype=object), 'video editing'),\n",
       " (array(['a graphic designer', 'someone', 'a video editor'], dtype=object),\n",
       "  'a video editor'))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_message = \"\"\"My name is Jack, the designer of Bellorita handbags (bellorita.com). We are working on a 90-second video ad on facebook. We need a video editor to help us edit the video with text, image, and footage overlay to go with the script and spokewoman.\n",
    "\n",
    "Right now the script (225 words) is ready, but the spokewoman video is not yet, and we need your suggestion on how we need her to performe to smooth your video editing.\n",
    "\n",
    "If you are interested, please propose with your price.\n",
    "\n",
    "Please note that this is an easy project, and we want the lowest rate possible. Thank you.\n",
    "\n",
    "I will pay through cash app and I need to sign an NDA\n",
    "\n",
    "Sincerely\n",
    "Jack\n",
    "\"\"\".lower()\n",
    "message = pre_process(raw_message)\n",
    "\n",
    "print(\"Breaking_2\") if step_1(raw_message, get_two_word(message), bad_keywords) else False\n",
    "print(step_1(raw_message, get_two_word(message), bad_keywords))\n",
    "\n",
    "\n",
    "find_workers(raw_message, message, parent_second), find_workers(raw_message, message, first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio(\"solid works\", \"solidworks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'class a ' in 'class aside'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\"\"\n",
    "a v \"\"\".lower().split())\n",
    "from ner import NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\"\"\n",
    "photoshop needed\n",
    "\"\"\".lower())\n",
    "extractor = NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import NER\n",
    "text = \"\"\"compensation: $60/hour\n",
    "\"\"\"\n",
    "def append_sapces(text):\n",
    "    if text.find(\"-\"): \n",
    "        (text[:text.find(\"-\")] + \" \" + text[text.find(\"-\")] + \" \" + text[text.find(\"-\")+1:])\n",
    "    if text.find(\"/\"):\n",
    "        (text[:text.find(\"/\")] + \" \" + text[text.find(\"/\")] + \" \" + text[text.find(\"/\")+1:])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': '60'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_entities_dict(append_sapces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': '60'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_entities_dict(append_sapces((text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDA']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_matching_key_word(message, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
