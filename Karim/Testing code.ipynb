{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kasem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kasem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df_keywords(df):\n",
    "    for column in df.columns:\n",
    "        for indx, entry in enumerate(df[column].dropna(axis=0)):\n",
    "            if len(entry.split()) > 1 and entry[-1] != \" \":\n",
    "                df[column][indx] = entry + \" \"\n",
    "def get_two_word(message):\n",
    "    combined_2_words = []\n",
    "    for word1, word2 in zip(message,list( message[1:] + list((message[0])))):\n",
    "        combined_2_words.append(word1 + ' ' + word2)\n",
    "    return combined_2_words\n",
    "\n",
    "def pre_process(message):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    pronouns = [\"we\", \"We\",\"WE\",\"I\",\"me\",\"Me\",\"ME\",\"THEY\",\"they\",\"They\",\"Them\",\"them\",\"THEM\",\"YOU\",\"You\",\"you\"]\n",
    "    result = []\n",
    "    for word in message.split():\n",
    "        if word not in stopWords and word not in pronouns:\n",
    "            result.append(word)\n",
    "    return (result)\n",
    "    \n",
    "def gen_len(iter):\n",
    "    return sum([1 for _ in iter])\n",
    "\n",
    "\n",
    "def isMatch_1_word(word1,word2,thresh=80): return (fuzz.QRatio(word1, word2) > thresh)\n",
    "def isMatch_many_words(word1,message,thresh=90): return (fuzz.partial_ratio(word1, message) >= thresh)\n",
    "\n",
    "def column_summary(word1, df):\n",
    "    summary = np.zeros(len(df.columns))\n",
    "    for col_indx, worker in enumerate(df.columns):\n",
    "        for word2 in df[worker].dropna(axis=0):\n",
    "            if isMatch_1_word(word1,word2):\n",
    "                summary[col_indx]+=1\n",
    "    return summary\n",
    "\n",
    "\n",
    "def summarize_one_words(message, first):\n",
    "    mat = np.zeros((len(message),len(first.columns)))\n",
    "    for word_indx, word in enumerate(message):    \n",
    "        mat[word_indx]=(column_summary(word,first)) \n",
    "    return mat\n",
    "\n",
    "def summarize_two_words(message, df):\n",
    "    mat = np.zeros((len(message),len(df.columns)))\n",
    "    for col_indx, worker in enumerate(df.columns):\n",
    "        two_words = df[df[worker].apply(lambda x: len(str(x).split())>1)][worker]\n",
    "        for word in two_words.dropna(axis=0):\n",
    "            for word_indx, two_word in enumerate(get_two_word(message)):\n",
    "                if isMatch_many_words(word, two_word):\n",
    "                    mat[word_indx][col_indx]+=1\n",
    "    return mat\n",
    "\n",
    "def find_workers(raw_message, message, first):\n",
    "    mat = summarize_one_words(message, first) + summarize_two_words(message, first)\n",
    "    #print(mat,\"\\n\\n\")\n",
    "    for word_indx, row_word in enumerate(mat[:]):\n",
    "        if row_word.sum() == 0:\n",
    "            mat[word_indx] = np.zeros((len(first.columns))); continue\n",
    "            \n",
    "        if len(first.columns[row_word != 0]) > 1:\n",
    "            mat[word_indx] = np.zeros((len(first.columns)))\n",
    "    \n",
    "    summary = np.array(mat).sum(axis=0)\n",
    "    match_worker = first.columns[summary!=0].values\n",
    "    summary_wo_zeros = summary[np.argwhere(summary).reshape(-1,1)]\n",
    "    \n",
    "    highest_match = \"\"\n",
    "    #print(mat)\n",
    "    #print(summary)\n",
    "    #print(f\"\"\"He is looking for >>> {match_worker}\"\"\")\n",
    "\n",
    "    if len(list(summary_wo_zeros)) != 0:\n",
    "        if summary_wo_zeros.max() != summary_wo_zeros.min():\n",
    "            highest_match = first.columns[np.argmax(summary)]\n",
    "    return match_worker, highest_match\n",
    "\n",
    "\n",
    "def find_matching_key_word(message, df):\n",
    "    results = []\n",
    "    for key_word in df[df.columns[0]]:\n",
    "        if any([isMatch_1_word(word,key_word) for word in message]):\n",
    "            results.append(key_word)\n",
    "        if any([isMatch_many_words(key_word, two_word) for two_word in get_two_word(message)]):\n",
    "            results.append(key_word)\n",
    "    return results\n",
    "\n",
    "def step_1(raw_message, message, bad_keywords):\n",
    "    matched_words = []\n",
    "    hard_coded = ['class a ', 'class b ', 'class c ']\n",
    "    one_words = bad_keywords[bad_keywords['name'].apply(lambda x: not len(x.split())>1)][\"name\"]\n",
    "    two_words = bad_keywords[bad_keywords['name'].apply(lambda x: len(x.split())>1)][\"name\"]\n",
    "    \n",
    "    for word in hard_coded: \n",
    "        if word in raw_message.lower(): matched_words.append(word)\n",
    "    for word in pre_process(raw_message):\n",
    "        if any([isMatch_1_word(word, word2, thresh=85) for word2 in one_words]): matched_words.append(word)\n",
    "    for word in two_words:\n",
    "        if any([isMatch_many_words(word, two_word) for two_word in message]): matched_words.append(word)\n",
    "    \n",
    "    return matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name\n",
       "0  contract\n",
       "1       NDA"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile('strings stems.xlsx')\n",
    "first = pd.read_excel(xls, 'first').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "parent_second = pd.read_excel(xls, 'parent second').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "bad_keywords= pd.read_excel(xls, 'bad keywords').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "at_least_another= pd.read_excel(xls, 'at least another').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "tutoring = pd.read_excel(xls, 'Tutoring').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "payments = pd.read_excel(xls, 'payments').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "contract = pd.read_excel(xls, 'contract').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "second_extract =  pd.read_csv('secondextract.csv').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "pre_process_df_keywords(first)\n",
    "pre_process_df_keywords(parent_second)\n",
    "pre_process_df_keywords(bad_keywords)\n",
    "\n",
    "print('x' in parent_second[\"sound effects\"].values)\n",
    "contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array(['video editing', 'creating similar websites'], dtype=object),\n",
       "  'video editing'),\n",
       " (array(['a video editor'], dtype=object), ''))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_message = \"\"\"Hello,\n",
    "\n",
    "We're looking for someone to become our new video editor for our entrepreneur video series. (Example: https://drive.google.com/open?id=1l2yGfmvyhGcSSyDi23Xl9PNe-AEKnjcv) We currently have over 30 videos (all are between 5 and 15 minutes long) that need to be edited, and we'll be asking you to edit more and more of them the longer we work together.\n",
    "\n",
    "You should be able to make high quality, HD video quickly and without any errors. The work is simple, but it needs your attention to make sure it feels personal, is well put together, and is aligned with our overall vision.\n",
    "\n",
    "Make sure that you include a couple of examples of similar style videos that you have edited in the past in your proposal. Also, include your price per edited video in your proposal. Any proposals that do not include a price per video in them will be dismissed immediately.\n",
    "\n",
    "tutor NDA cash app\n",
    "\n",
    "Here is examples on Pinterest.\n",
    "\"\"\".lower()\n",
    "message = pre_process(raw_message)\n",
    "\n",
    "print(\"Breaking_2\") if step_1(raw_message, get_two_word(message), bad_keywords) else False\n",
    "print(step_1(raw_message, get_two_word(message), bad_keywords))\n",
    "\n",
    "\n",
    "find_workers(raw_message, message, parent_second), find_workers(raw_message, message, first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio(\"solid works\", \"solidworks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'class a ' in 'class aside'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\"\"\n",
    "a v \"\"\".lower().split())\n",
    "from ner import NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\"\"\n",
    "photoshop needed\n",
    "\"\"\".lower())\n",
    "extractor = NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import NER\n",
    "text = \"\"\"compensation: $60/hour\n",
    "\"\"\"\n",
    "def append_sapces(text):\n",
    "    if text.find(\"-\"): \n",
    "        (text[:text.find(\"-\")] + \" \" + text[text.find(\"-\")] + \" \" + text[text.find(\"-\")+1:])\n",
    "    if text.find(\"/\"):\n",
    "        (text[:text.find(\"/\")] + \" \" + text[text.find(\"/\")] + \" \" + text[text.find(\"/\")+1:])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': '60'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_entities_dict(append_sapces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': '60'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_entities_dict(append_sapces((text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cash app']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_matching_key_word(message, payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"intern\",\"international\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
